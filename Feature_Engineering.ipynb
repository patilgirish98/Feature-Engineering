{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Assignment Questions :"
      ],
      "metadata": {
        "id": "Ayg9YQVou5Ib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter\n",
        "\n",
        "   - In statistics, a parameter is a numerical value that describes a\n",
        "     characteristic of a population.\n",
        "   - It is fixed but unknown (unless we measure the entire population).\n",
        "   - Common parameters include:\n",
        "      - Population mean (μ)\n",
        "      - Population standard deviation (σ)\n",
        "      - Population proportion (p)\n",
        "\n",
        "2. What is correlation ?\n",
        "\n",
        "   - Correlation is a statistical measure that describes the strength and\n",
        "     direction of a relationship between two variables.\n",
        "   - Range: Correlation values range from -1 to +1.\n",
        "      - +1 → perfect positive correlation (both increase together)\n",
        "      - -1 → perfect negative correlation (one increases, the other decreases)\n",
        "      - 0 → no linear relationship\n",
        "   - The most common measure is the Pearson correlation coefficient (r), which\n",
        "     measures linear relationships.\n",
        "\n",
        "\n",
        "3. Define Machine Learning. What are the main components in Machine Learning\n",
        "\n",
        "   - Machine Learning (ML) is a subset of artificial intelligence (AI) that\n",
        "     focuses on developing algorithms that allow computers to learn from and make predictions or decisions based on data—without being explicitly programmed for every task.\n",
        "   - Main Components of Machine Learning:\n",
        "      - Data\n",
        "      - Modal\n",
        "      - Algorithm\n",
        "      - Traning\n",
        "      - Features\n",
        "      - Labels\n",
        "      - Loss Function\n",
        "      - Optimization\n",
        "\n",
        "\n",
        "4. How does loss value help in determining whether the model is good or not ?\n",
        "\n",
        "    - The loss value is a quantitative measure of how well or poorly a machine\n",
        "      learning model is performing. It represents the difference between the predicted output and the actual output.\n",
        "    - Lower loss means better model performance on the training or validation\n",
        "      data.\n",
        "    - A high loss indicates that the model’s predictions are far from the true\n",
        "      values.\n",
        "    - Example:\n",
        "       - For a regression problem:\n",
        "          - Loss function: Mean Squared Error (MSE)\n",
        "          - MSE = 0 → Perfect predictions\n",
        "          - MSE = high → Poor predictions\n",
        "\n",
        "5. What are continuous and categorical variables ?\n",
        "\n",
        "   - Continuous variables: Can take any numeric value within a range (e.g.,\n",
        "     height, weight, temperature).\n",
        "   - Categorical variables: Represent groups or categories (e.g., gender,  \n",
        "     color, type).\n",
        "\n",
        "\n",
        "6. How do we handle categorical variables in Machine Learning? What are the\n",
        "   common techniques ?\n",
        "\n",
        "    - Categorical variables must be converted to numeric format before being\n",
        "      used in most ML models.\n",
        "    1. Label Encoding – assigns numbers to categories.\n",
        "    2. One-Hot Encoding – creates binary columns for each category.\n",
        "    3. Ordinal Encoding – for ordered categories.\n",
        "    4. Target Encoding – uses target averages (used carefully).\n",
        "\n",
        "\n",
        "7. What do you mean by training and testing a dataset ?\n",
        "\n",
        "    - Training a dataset means using data to teach the model to recognize\n",
        "      patterns and make predictions.\n",
        "    - Testing a dataset means using new, unseen data to evaluate how well the\n",
        "      model performs.\n",
        "    -  Example:\n",
        "        - Training Set → Model learns from this.\n",
        "        - Testing Set → Model is tested on this to check accuracy or\n",
        "          performance.\n",
        "\n",
        "8. What is sklearn.preprocessing ?\n",
        "\n",
        "   - sklearn.preprocessing is a module in Scikit-learn that provides tools to\n",
        "     prepare or transform data before feeding it into a machine learning model.\n",
        "       - Scaling features (StandardScaler, MinMaxScaler)\n",
        "       - Encoding categories (LabelEncoder, OneHotEncoder)\n",
        "       - Handling missing values (SimpleImputer)\n",
        "\n",
        "9. What is a Test set ?\n",
        "\n",
        "   - A test set is a portion of data kept separate from the training process  \n",
        "     and used to evaluate the performance of a trained machine learning model on new, unseen data. It helps check how well the model generalizes.\n",
        "\n",
        "\n",
        "10. How do we split data for model fitting (training and testing) in Python ?\n",
        "\n",
        "   - You can split data into training and testing sets in Python using\n",
        "     train_test_split from scikit-learn like this:\n",
        "   - In machine learning, data is typically divided into two parts:\n",
        "   1. Training set: Used to train or fit the model — the algorithm learns\n",
        "     patterns from this data.\n",
        "   2. Test set: Used to evaluate the model’s performance on unseen data,\n",
        "     assessing how well it generalizes.\n",
        "\n",
        "\n",
        "11. Why do we have to perform EDA before fitting a model to the data ?\n",
        "\n",
        "   - Exploratory Data Analysis (EDA) helps you understand the data before\n",
        "     building a machine learning model.\n",
        "   - Here’s why it’s important:\n",
        "      1. Identify Data Quality Issues\n",
        "      2. Understand Data Distribution\n",
        "      3. Discover Relationships and Patterns\n",
        "      4. Choose the Right Model and Techniques\n",
        "      5. Avoid Garbage In, Garbage Out\n",
        "\n",
        "12. What is correlation ?\n",
        "\n",
        "   - Correlation measures the strength and direction of a relationship between two variables.\n",
        "   - It ranges from -1 to +1:\n",
        "      - +1 means perfect positive correlation (both increase together)\n",
        "      - -1 means perfect negative correlation (one increases, the other\n",
        "        decreases),\n",
        "      - 0 means no linear relationship.\n",
        "\n",
        "\n",
        "13. What does negative correlation mean ?\n",
        "\n",
        "   - Negative correlation means that as one variable increases, the other\n",
        "     variable decreases, and vice versa.\n",
        "   - The correlation value is between -1 and 0.\n",
        "   - A value close to -1 indicates a strong negative relationship.\n",
        "   - Example: More time spent watching TV might be negatively correlated with\n",
        "     test scores—when TV time goes up, scores tend to go down.\n",
        "\n",
        "\n",
        "14. What is causation? Explain difference between correlation and causation  \n",
        "     with an example\n",
        "\n",
        "    - Difference between Correlation and Causation\n",
        "    - Correlation means there is a relationship or association between two\n",
        "      variables — when one changes, the other tends to change too. But this doesnt mean one causes the other\n",
        "    - Causation means one variable directly influences the other.\n",
        "    -Example:\n",
        "       - Correlation example: Ice cream sales and drowning incidents both\n",
        "         increase during summer. These two are correlated because both happen more often in hot weather, but ice cream sales do not cause drowning.\n",
        "\n",
        "\n",
        "15. What is an Optimizer? What are different types of optimizers? Explain each\n",
        "     with an example ?\n",
        "\n",
        "     - An optimizer is an algorithm or method used to adjust the parameters     (like weights) of a machine learning model to minimize the loss function (error) during training. The goal of the optimizer is to find the best set of parameters that reduces the difference between the predicted output and the actual output.\n",
        "     - Different Types of Optimizers and Explanation\n",
        "     1. Gradient Descent (GD)\n",
        "         - How it works: It updates the parameters by moving them in the\n",
        "           direction opposite to the gradient of the loss function to reduce the error.\n",
        "     2. Momentum\n",
        "         - How it works: Momentum helps accelerate gradient descent by adding   fraction of the previous update to the current update. It helps the optimizer build speed in consistent gradient directions and avoid getting stuck in small local minima.\n",
        "         - Example: Imagine pushing a ball down a slope — momentum keeps it\n",
        "           rolling faster over time rather than restarting at each step.\n",
        "     3. Adagrad\n",
        "         - How it works: It adapts the learning rate for each parameter based  \n",
        "          on how frequently it is updated — parameters updated frequently get smaller learning rates, and rarely updated parameters get larger learning rates.\n",
        "         - Example: Useful when dealing with sparse data or features (like text\n",
        "          data).\n",
        "\n",
        "16. What is sklearn.linear_model ?\n",
        "\n",
        "   - sklearn.linear_model is a module in the popular Python machine learning library scikit-learn (sklearn) that provides a variety of linear models for regression and classification tasks.\n",
        "      - LinearRegression: Ordinary least squares linear regression for        continuous targets\n",
        "      - LogisticRegression: Linear model for classification problems (predicts\n",
        "        probabilities and classes).\n",
        "      - Ridge: Linear regression with L2 regularization to prevent overfitting.\n",
        "      - Lasso: Linear regression with L1 regularization that can perform  \n",
        "        feature selection by shrinking some coefficients to zero.\n",
        "      - ElasticNet: Combination of L1 and L2 regularization.\n",
        "\n",
        "\n",
        "18. What does model.fit() do? What arguments must be given ?\n",
        "\n",
        "   - The .fit() method is used to train a machine learning model. When you call\n",
        "     model.fit(), the model learns from the training data by finding the best parameters (like weights in linear regression) that minimize the error or loss function.\n",
        "   - In other words, .fit() adjusts the internal state of the model based on  \n",
        "     the data you provide so that it can make good predictions later.\n",
        "\n",
        "\n",
        "19. What does model.predict() do? What arguments must be given ?\n",
        "\n",
        "   - The .predict() method is used to make predictions with a trained machine\n",
        "     learning model. After you train your model using .fit(), you use .predict() to estimate the output (target values) for new, unseen input data.\n",
        "   - Basically, .predict() takes new data and uses the learned parameters to\n",
        "     predict the labels or values.\n",
        "   - The .predict() method requires one argument:\n",
        "      - A 2D array or dataframe containing the new samples you want to predict.\n",
        "        The shape and number of features must match the data used during training.\n",
        "\n",
        "\n",
        "20. What are continuous and categorical variables ?\n",
        "\n",
        "    - Continuous Variables\n",
        "       - Definition: Variables that can take any numerical value within a range (often infinite possibilities).\n",
        "       - Characteristics: They are measurable and can be fractional or decimal\n",
        "       - Examples:\n",
        "           - Height (e.g., 172.5 cm)\n",
        "           -  Temperature (e.g., 23.8 °C)\n",
        "           - Weight (e.g., 65.2 kg)\n",
        "           -Age (e.g., 25.6 years)\n",
        "\n",
        "    - Categorical Variables\n",
        "       - Definition: Variables that represent categories or groups.\n",
        "       - Characteristics: They take on a limited, fixed number of possible values, which are often labels or names.\n",
        "       - Examples:\n",
        "            - Gender (e.g., Male, Female)\n",
        "            - Color (e.g., Red, Blue, Green)\n",
        "            - Type of animal (e.g., Dog, Cat, Bird)\n",
        "            -Payment method (e.g., Credit Card, Cash, PayPal)\n",
        "\n",
        "  \n",
        "\n",
        "21. What is feature scaling? How does it help in Machine Learning ?\n",
        "\n",
        "    - Feature scaling is the process of normalizing or standardizing the range\n",
        "      of independent variables (features) in your data. It transforms features so that they have a similar scale — usually within a specific range (like 0 to 1) or with a mean of 0 and standard deviation of 1.\n",
        "    - Why is Feature Scaling important?\n",
        "       - Many machine learning algorithms work better or converge faster when\n",
        "         features are on a similar scale. Without scaling, features with larger ranges can dominate the learning process, causing problems like:\n",
        "       - Slow convergence of optimization algorithms (like gradient descent).\n",
        "       - Poor performance because the algorithm assumes all features contribute\n",
        "         equally.\n",
        "       - Bias in distance-based algorithms, where features with larger numeric  ranges overshadow others.\n",
        "\n",
        "\n",
        "22. How do we perform scaling in Python\n",
        "\n",
        "   - Performing feature scaling in Python is straightforward, especially using scikit-learn (sklearn). Here’s how you can do it for the two common methods: Min-Max Scaling and Standardization.\n",
        "   - How it works:\n",
        "      - fit() learns the parameters (min, max, mean, std) from training data.\n",
        "      - transform() applies the scaling using those parameters.\n",
        "      - fit_transform() does both in one step.\n",
        "\n",
        "\n",
        "23. What is sklearn.preprocessing ?\n",
        "\n",
        "   - sklearn.preprocessing is a module in the scikit-learn library that  \n",
        "     provides various utilities and functions to preprocess and transform raw data into a form that is better suited for machine learning algorithms.\n",
        "   - What does sklearn.preprocessing include?\n",
        "      - Scaling features (e.g., Min-Max scaling, Standardization)\n",
        "      - Encoding categorical variables (e.g., One-Hot Encoding, Label Encoding)\n",
        "      - Normalizing data\n",
        "      - Binarizing data (converting features to binary)\n",
        "      - Generating polynomial features\n",
        "\n",
        "\n",
        "24. How do we split data for model fitting (training and testing) in Python ?\n",
        "\n",
        "    - Splitting data into training and testing sets is a crucial step to       evaluate how well your machine learning model generalizes to unseen data.\n",
        "    - Explanation:\n",
        "    - test_size: Fraction of the dataset to be used as the test set (e.g., 0.2\n",
        "      means 20% test data)\n",
        "    - random_state: Seed for reproducibility. Using the same value ensures the\n",
        "      split is the same every time you run it.\n",
        "    - By default, data is shuffled before splitting to ensure randomness.\n",
        "\n",
        "\n",
        "25. Explain data encoding ?\n",
        "\n",
        "   - Data encoding is the process of converting categorical or non-numeric data\n",
        "     into a numerical format that machine learning algorithms can understand and work with.\n",
        "   - Since most ML algorithms require numeric input, encoding transforms\n",
        "     categories (like “red,” “blue,” “green”) or text labels into numbers.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kVXlUSSwu9La"
      }
    }
  ]
}